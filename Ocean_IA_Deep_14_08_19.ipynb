{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando dependências\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando os dados de treino e teste\n",
    "\n",
    "(x_treino, y_treino), (x_teste, y_teste) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagens de Treino: 60000\n",
      "Imagens de Teste: 10000\n",
      "Formato da imagem: (28, 28)\n",
      "Representação da imagem x_treino[0]: 5\n",
      "Dados da imagem: [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      "  225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
      "   93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
      "   25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      "  150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
      "  253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
      "  253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      "  253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
      "  250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
      "   78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "# Exibindo como estão os dados\n",
    "\n",
    "# Quantas imagens para treino?\n",
    "print(\"Imagens de Treino:\", len(x_treino))\n",
    "\n",
    "# Quantas imagens para teste?\n",
    "print(\"Imagens de Teste:\", len(x_teste))\n",
    "\n",
    "# Qual o formato de uma imagem?\n",
    "print(\"Formato da imagem:\", x_treino[0].shape)\n",
    "\n",
    "# O que a imagem x_treino[0] representa?\n",
    "print(\"Representação da imagem x_treino[0]:\", y_treino[0])\n",
    "\n",
    "# Como são os dados de uma imagem?\n",
    "print(\"Dados da imagem:\", x_treino[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digite um número válido entre 0 e 5999915432\n",
      "Essa imagem representa: 4\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Exibindo a imagem\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Configuração para o jupyter notebook exibir a imagem corretamente\n",
    "%matplotlib inline\n",
    "\n",
    "indice = 0\n",
    "\n",
    "# Se quiser perguntar para o usuário um número de índice:\n",
    "#indice = int(input(\"Digite um número válido entre 0 e 59999: \"))\n",
    "\n",
    "print(\"Essa imagem representa:\", y_treino[indice])\n",
    "plt.imshow(x_treino[indice], cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Achatando as matrizes de pixels e transformando em uma única lista com valores\n",
    "\n",
    "quantidade_treino = len(x_treino) # Vai me trazer 60000\n",
    "quantidade_teste = len(x_teste) # Vai me trazer 10000\n",
    "\n",
    "tamanho_imagem = x_treino[0].shape # Vai me trazer (28, 28)\n",
    "tamanho_total = tamanho_imagem[0] * tamanho_imagem[1] # Vai me trazer 784\n",
    "\n",
    "x_treino = x_treino.reshape(quantidade_treino, tamanho_total)\n",
    "x_teste = x_teste.reshape(quantidade_teste, tamanho_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Novo formato dos dados: (784,)\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   3  18  18  18 126 136 175  26 166 255\n",
      " 247 127   0   0   0   0   0   0   0   0   0   0   0   0  30  36  94 154\n",
      " 170 253 253 253 253 253 225 172 253 242 195  64   0   0   0   0   0   0\n",
      "   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251  93  82\n",
      "  82  56  39   0   0   0   0   0   0   0   0   0   0   0   0  18 219 253\n",
      " 253 253 253 253 198 182 247 241   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0  14   1 154 253  90   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0  11 190 253  70   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  35 241\n",
      " 225 160 108   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0  81 240 253 253 119  25   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  45 186 253 253 150  27   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252 253 187\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0 249 253 249  64   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      " 253 207   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0  39 148 229 253 253 253 250 182   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253\n",
      " 253 201  78   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  23  66 213 253 253 253 253 198  81   2   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  18 171 219 253 253 253 253 195\n",
      "  80   9   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  55 172 226 253 253 253 253 244 133  11   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0 136 253 253 253 212 135 132  16\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "# Visualizar dados achatados\n",
    "\n",
    "print(\"Novo formato dos dados:\", x_treino[0].shape)\n",
    "print(x_treino[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalização dos dados\n",
    "\n",
    "# Converte todos os valores de int8 para float32\n",
    "x_treino = x_treino.astype('float32')\n",
    "x_teste = x_teste.astype('float32')\n",
    "\n",
    "# Valores entre 0 e 255 ficarão entre 0 e 1\n",
    "x_treino /= 255\n",
    "x_teste /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados normalizados\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.01176471 0.07058824 0.07058824 0.07058824\n",
      " 0.49411765 0.53333336 0.6862745  0.10196079 0.6509804  1.\n",
      " 0.96862745 0.49803922 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.11764706 0.14117648 0.36862746 0.6039216\n",
      " 0.6666667  0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
      " 0.88235295 0.6745098  0.99215686 0.9490196  0.7647059  0.2509804\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.19215687\n",
      " 0.93333334 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
      " 0.99215686 0.99215686 0.99215686 0.9843137  0.3647059  0.32156864\n",
      " 0.32156864 0.21960784 0.15294118 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.07058824 0.85882354 0.99215686\n",
      " 0.99215686 0.99215686 0.99215686 0.99215686 0.7764706  0.7137255\n",
      " 0.96862745 0.94509804 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.3137255  0.6117647  0.41960785 0.99215686\n",
      " 0.99215686 0.8039216  0.04313726 0.         0.16862746 0.6039216\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.05490196 0.00392157 0.6039216  0.99215686 0.3529412\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.54509807 0.99215686 0.74509805 0.00784314 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.04313726\n",
      " 0.74509805 0.99215686 0.27450982 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.13725491 0.94509804\n",
      " 0.88235295 0.627451   0.42352942 0.00392157 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.31764707 0.9411765  0.99215686\n",
      " 0.99215686 0.46666667 0.09803922 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.1764706  0.7294118  0.99215686 0.99215686\n",
      " 0.5882353  0.10588235 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.0627451  0.3647059  0.9882353  0.99215686 0.73333335\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.9764706  0.99215686 0.9764706  0.2509804  0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.18039216 0.50980395 0.7176471  0.99215686\n",
      " 0.99215686 0.8117647  0.00784314 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.15294118 0.5803922\n",
      " 0.8980392  0.99215686 0.99215686 0.99215686 0.98039216 0.7137255\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.09411765 0.44705883 0.8666667  0.99215686 0.99215686 0.99215686\n",
      " 0.99215686 0.7882353  0.30588236 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.09019608 0.25882354 0.8352941  0.99215686\n",
      " 0.99215686 0.99215686 0.99215686 0.7764706  0.31764707 0.00784314\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.07058824 0.67058825\n",
      " 0.85882354 0.99215686 0.99215686 0.99215686 0.99215686 0.7647059\n",
      " 0.3137255  0.03529412 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.21568628 0.6745098  0.8862745  0.99215686 0.99215686 0.99215686\n",
      " 0.99215686 0.95686275 0.52156866 0.04313726 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.53333336 0.99215686\n",
      " 0.99215686 0.99215686 0.83137256 0.5294118  0.5176471  0.0627451\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "# Visualizando os dados normalizados\n",
    "\n",
    "print(\"Dados normalizados\")\n",
    "print(x_treino[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de Valores Únicos em y_treino: 10\n",
      "y_treino[0] antes: 5\n",
      "y_treino[0] depois: [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Transformando y_treino e y_teste para variáveis categóricas\n",
    "\n",
    "valores_unicos = set(y_treino) # Irá me trazer os itens únicos: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n",
    "qtde_valores_unicos = len(valores_unicos) # Irá me trazer que são 10 itens únicos\n",
    "print(\"Quantidade de Valores Únicos em y_treino:\", qtde_valores_unicos)\n",
    "\n",
    "# O que temos em y_treino[0]?\n",
    "print(\"y_treino[0] antes:\", y_treino[0])\n",
    "\n",
    "# Transforma 1 em [0, 1, 0, 0, 0, 0, 0, 0, 0], 2 em [0, 0, 1, 0, 0, 0, 0, 0, 0] e assim por diante\n",
    "y_treino = keras.utils.to_categorical(y_treino, qtde_valores_unicos)\n",
    "y_teste = keras.utils.to_categorical(y_teste, qtde_valores_unicos)\n",
    "\n",
    "# Como ficou y_treino[0] depois da transformação?\n",
    "print(\"y_treino[0] depois:\", y_treino[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\paulo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From c:\\users\\paulo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 30)                23550     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 20)                620       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 24,380\n",
      "Trainable params: 24,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Criando o modelo\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Primeira hidden layer com 30 neurônios, com função de ativação ReLU\n",
    "# Na primeira camada, precisamos definir o input shape, que no caso será (784,)\n",
    "model.add(Dense(30, activation='relu', input_shape=(tamanho_total,)))\n",
    "\n",
    "# Adicionamos um regularizador. No caso, será um Dropout\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Segunda hidden layer com 20 neurônios, com função de ativação ReLU\n",
    "model.add(Dense(20, activation='relu'))\n",
    "\n",
    "# Mais um regularizador depois da segunda hidden layer\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Finalizamos com a camada de output, com a quantidade de valores únicos (no caso 10) e uma\n",
    "# função de ativação Softmax\n",
    "model.add(Dense(qtde_valores_unicos, activation='softmax'))\n",
    "\n",
    "# Exibimos o resumo do modelo criado\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compila o modelo criado\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer=RMSprop(),\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\paulo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.8731 - acc: 0.7285 - val_loss: 0.2990 - val_acc: 0.9142\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.4499 - acc: 0.8655 - val_loss: 0.2306 - val_acc: 0.9315\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3823 - acc: 0.8878 - val_loss: 0.2054 - val_acc: 0.9393\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3408 - acc: 0.9008 - val_loss: 0.1943 - val_acc: 0.9422\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3140 - acc: 0.9093 - val_loss: 0.1834 - val_acc: 0.9478\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3008 - acc: 0.9135 - val_loss: 0.1790 - val_acc: 0.9496\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2889 - acc: 0.9166 - val_loss: 0.1718 - val_acc: 0.9514\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2761 - acc: 0.9208 - val_loss: 0.1615 - val_acc: 0.9551\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2701 - acc: 0.9237 - val_loss: 0.1623 - val_acc: 0.9555\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2659 - acc: 0.9235 - val_loss: 0.1643 - val_acc: 0.9560\n"
     ]
    }
   ],
   "source": [
    "# Treina o modelo\n",
    "\n",
    "history = model.fit(x_treino, y_treino,\n",
    "                   batch_size=128,\n",
    "                   epochs=10,\n",
    "                   verbose=1,\n",
    "                   validation_data=(x_teste, y_teste))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valor em y_teste[indice] [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "Previsão: [[8.9865011e-07 1.4739011e-07 1.0730946e-06 6.9979633e-06 7.3206765e-03\n",
      "  2.1834157e-05 1.6330453e-08 3.7525103e-03 4.9434971e-07 9.8889530e-01]]\n",
      "Previsão (ajustada): [9]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e606537438>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAADolJREFUeJzt3X+sVPWZx/HPA6IYivEHF7jhx962IUaDga4TslHc4K9q1yZYSU0xApqmoNa4RKJriKaauITgloqJIQElxaQVGgsrJmRboiVujaKjQbCLuyXmWhCEi/gD/lAEnv3jHpor3vnOOGdmztz7vF+JmZnznDPnycjnnpn5zjlfc3cBiGdI0Q0AKAbhB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8Q1Bmt3NmoUaO8q6urlbsEQunu7tahQ4eslnVzhd/Mrpe0QtJQSU+5+9LU+l1dXSqXy3l2CSChVCrVvG7db/vNbKikJyX9QNLFkmab2cX1Ph+A1srzmX+apN3u/p67H5O0TtLMxrQFoNnyhH+cpD19Hu/Nln2Fmc03s7KZlXt6enLsDkAj5Ql/f18qfO38YHdf5e4ldy91dHTk2B2ARsoT/r2SJvR5PF7SvnztAGiVPOF/Q9IkM/u2mZ0p6SeSNjWmLQDNVvdQn7sfN7O7Jf1BvUN9a9z9Lw3rDEBT5Rrnd/fNkjY3qBcALcTPe4GgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwgq1yy9ZtYt6YikE5KOu3upEU0BaL5c4c9c6e6HGvA8AFqIt/1AUHnD75L+aGZvmtn8RjQEoDXyvu2/3N33mdloSVvM7F13f7nvCtkfhfmSNHHixJy7A9AouY787r4vuz0oaaOkaf2ss8rdS+5e6ujoyLM7AA1Ud/jNbISZjTx1X9L3Jb3TqMYANFeet/1jJG00s1PP81t3/6+GdAWg6eoOv7u/J2lKA3sB0EIM9QFBEX4gKMIPBEX4gaAIPxAU4QeCasRZfRjAdu/enawfOpQ+YXPjxo3J+tatWyvWhgxJH3vuuOOOZP2yyy5L1idNmpSsR8eRHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCYpx/ENi5c2fF2pNPPpncdsOGDcl6T09PXT01wmuvvZasDxs2LFm/8MILK9amT5+e3HbFihXJ+plnnpmsDwQc+YGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMb528COHTuS9Wpj9evXr69Y+/TTT+vq6ZTx48cn61dccUWy3tXVVbH22GOPJbe99NJLk/Vt27Yl6x999FHF2ubNm5PbTpmSvip9tWsNDAQc+YGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gqKrj/Ga2RtIPJR1098nZsvMlrZfUJalb0s3u/nHz2hzYFixYkKxXu/Z9nnPqr7nmmmT9kksuSdaXLFmSrA8fPvwb93TKq6++mqyvXLkyWb/99tuT9e3bt1esjR07NrntXXfdlazPmjUrWe/o6EjW20EtR/5fS7r+tGUPSHrR3SdJejF7DGAAqRp+d39Z0uHTFs+UtDa7v1bSjQ3uC0CT1fuZf4y775ek7HZ041oC0ApN/8LPzOabWdnMykVeDw7AV9Ub/gNm1ilJ2e3BSiu6+yp3L7l7aSB8CQJEUW/4N0mal92fJ+n5xrQDoFWqht/MnpX0qqQLzWyvmf1U0lJJ15rZXyVdmz0GMIBUHed399kVSlc3uJe29vnnn1esLVu2LLnt6tWrk3V3T9ZHj05/n3rnnXdWrN13333JbUeMGJGsN1PqfHtJOn78eLL+yCOPJOvXXXddxVp3d3dy2wj4hR8QFOEHgiL8QFCEHwiK8ANBEX4gKC7dXaOtW7dWrFW7BHW1obxx48Yl69Wm0Z42bVqy3kwnTpxI1vfs2VOxNnfu3OS2N9xwQ7L+8cfNO4t8zpw5yfq5557btH23Ckd+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiKcf4apU4vHTp0aK7nHjZsWLJebSrq5557rmLt3XffraunU84+++xkfdeuXXXXR40aldz2ww8/TNbzGDNmTLL+4IMPJuvV/p8NBBz5gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAoxvlrdPXVla9UfuWVVya33bJlS7L+/vvvJ+v33HNPsp7HGWek/wlUu3x2HnnH8YcMSR+7brrppoq1J554IrltZ2dnXT0NJBz5gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiCoquP8ZrZG0g8lHXT3ydmyhyX9TFJPttpid9/crCbbQeq89o0bNya3/eSTT5L1pUuXJuuvvPJKsn7BBRdUrE2cODG57RdffJGsv/3228l6tWsNNNOCBQuS9SVLllSsDYbr7udVy5H/15Ku72f5r9x9avbfoA4+MBhVDb+7vyzpcAt6AdBCeT7z321mO8xsjZmd17COALREveFfKem7kqZK2i/pl5VWNLP5ZlY2s3JPT0+l1QC0WF3hd/cD7n7C3U9KWi2p4kyR7r7K3UvuXuro6Ki3TwANVlf4zazvKU8/kvROY9oB0Cq1DPU9K2mGpFFmtlfSLyTNMLOpklxSt6T0mAuAtlM1/O4+u5/FTzehl0Gr2phytXH+Is2dOzdZzzPOf8455yTry5cvT9Zvu+22ZD3vfAqDHb/wA4Ii/EBQhB8IivADQRF+ICjCDwTFpbuDW7ZsWbK+bt26pu175cqVyfott9zStH2DIz8QFuEHgiL8QFCEHwiK8ANBEX4gKMIPBMU4/yD31FNPJeuPPvposv7ll1/m2v/kyZMr1mbNmpXruZEPR34gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIpx/kHg9ddfr1hbtGhRctsjR47k2vfIkSOT9dQ5+2eddVaufSMfjvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EFTVcX4zmyDpGUljJZ2UtMrdV5jZ+ZLWS+qS1C3pZnf/uHmtopIXXnihYu2zzz7L9dwjRoxI1jdt2pSsT58+Pdf+0Ty1HPmPS1rk7hdJ+idJPzeziyU9IOlFd58k6cXsMYABomr43X2/u7+V3T8iaZekcZJmSlqbrbZW0o3NahJA432jz/xm1iXpe5K2SRrj7vul3j8QkkY3ujkAzVNz+M3sW5J+L2mhu9f8QdLM5ptZ2czKPT099fQIoAlqCr+ZDVNv8H/j7huyxQfMrDOrd0o62N+27r7K3UvuXuro6GhEzwAaoGr4zcwkPS1pl7sv71PaJGledn+epOcb3x6AZqnllN7LJc2RtNPMtmfLFktaKul3ZvZTSX+T9OPmtIhqp91Wm2Y7j1tvvTVZnzFjRtP2jeaqGn53/7Mkq1C+urHtAGgVfuEHBEX4gaAIPxAU4QeCIvxAUIQfCIpLd7eBo0ePJusXXXRRsn7s2LG69z1lypRk/fHHH6/7udHeOPIDQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCM87eBl156KVn/4IMPmrbv5cuXJ+vDhw9v2r5RLI78QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4/xt4KGHHmrac99///3J+lVXXdW0faO9ceQHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaCqjvOb2QRJz0gaK+mkpFXuvsLMHpb0M0k92aqL3X1zsxodzA4fPpxr+9GjR1esLVy4MNdzY/Cq5Uc+xyUtcve3zGykpDfNbEtW+5W7/0fz2gPQLFXD7+77Je3P7h8xs12SxjW7MQDN9Y0+85tZl6TvSdqWLbrbzHaY2RozO6/CNvPNrGxm5Z6env5WAVCAmsNvZt+S9HtJC939M0krJX1X0lT1vjP4ZX/bufsqdy+5e6mjo6MBLQNohJrCb2bD1Bv837j7Bkly9wPufsLdT0paLWla89oE0GhVw29mJulpSbvcfXmf5Z19VvuRpHca3x6AZqnl2/7LJc2RtNPMtmfLFkuabWZTJbmkbkkLmtJhAPfee2+ueuqU4M7Ozoo1xFbLt/1/lmT9lBjTBwYwfuEHBEX4gaAIPxAU4QeCIvxAUIQfCMrcvWU7K5VKXi6XW7Y/IJpSqaRyudzf0PzXcOQHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaBaOs5vZj2S3u+zaJSkQy1r4Jtp197atS+J3urVyN7+wd1rul5eS8P/tZ2bld29VFgDCe3aW7v2JdFbvYrqjbf9QFCEHwiq6PCvKnj/Ke3aW7v2JdFbvQrprdDP/ACKU/SRH0BBCgm/mV1vZv9rZrvN7IEieqjEzLrNbKeZbTezQs8/zqZBO2hm7/RZdr6ZbTGzv2a3/U6TVlBvD5vZB9lrt93M/qWg3iaY2Z/MbJeZ/cXM/jVbXuhrl+irkNet5W/7zWyopP+TdK2kvZLekDTb3f+npY1UYGbdkkruXviYsJn9s6Sjkp5x98nZsmWSDrv70uwP53nu/m9t0tvDko4WPXNzNqFMZ9+ZpSXdKOk2FfjaJfq6WQW8bkUc+adJ2u3u77n7MUnrJM0soI+25+4vSzp82uKZktZm99eq9x9Py1XorS24+353fyu7f0TSqZmlC33tEn0Voojwj5O0p8/jvWqvKb9d0h/N7E0zm190M/0Yk02bfmr69NEF93O6qjM3t9JpM0u3zWtXz4zXjVZE+Pu7xFA7DTlc7u7/KOkHkn6evb1FbWqaublV+plZui3UO+N1oxUR/r2SJvR5PF7SvgL66Je778tuD0raqPabffjAqUlSs9uDBffzd+00c3N/M0urDV67dprxuojwvyFpkpl928zOlPQTSZsK6ONrzGxE9kWMzGyEpO+r/WYf3iRpXnZ/nqTnC+zlK9pl5uZKM0ur4Neu3Wa8LuRHPtlQxuOShkpa4+7/3vIm+mFm31Hv0V7qncT0t0X2ZmbPSpqh3rO+Dkj6haT/lPQ7SRMl/U3Sj9295V+8Vehthnrfuv595uZTn7Fb3Nt0Sf8taaekk9nixer9fF3Ya5foa7YKeN34hR8QFL/wA4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8Q1P8D5IUUdS3T+BkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fazendo nossas previsões\n",
    "\n",
    "indice = 9\n",
    "\n",
    "# Qual o valor categórico de y_teste[indice]?\n",
    "print(\"Valor em y_teste[indice]\", y_teste[indice])\n",
    "# y_teste[indice] irá me trazer [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.], por tanto, deve ser um 7\n",
    "\n",
    "# Reajustando a imagem em x_teste[indice]\n",
    "imagem = x_teste[indice].reshape((1, tamanho_total))\n",
    "\n",
    "# Fazendo minha previsão\n",
    "prediction = model.predict(imagem) # Irá retornar os valores de cada posição do output\n",
    "print(\"Previsão:\", prediction)\n",
    "\n",
    "# Ajustando a previsão para o número real\n",
    "prediction_class = model.predict_classes(imagem)\n",
    "print(\"Previsão (ajustada):\", prediction_class)\n",
    "\n",
    "(x_treino_img, y_treino_img), (x_teste_img, y_teste_img) = mnist.load_data()\n",
    "plt.imshow(x_teste_img[indice], cmap=plt.cm.binary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
